{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this sections, we will learn to train a machine learning model on the existing sentiment data and try to predict sentiment of the news headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (BoW)\n",
    "Bag of words take words in documents and find out the frequency of each word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love dogs',\n",
       " 'I hate dogs and knitting',\n",
       " 'Knitting is my hobby and my passion']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "'I love dogs',\n",
    "'I hate dogs and knitting',\n",
    "'Knitting is my hobby and my passion']\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of Words\n",
    "First, we will import CountVectorizer from sklearn and instantiate as an object. CountVectorizer separates each sentence into tokens, and then count the number of times each token occurs in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Instantiate CountVectorizer()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Fit the model\n",
    "word_count = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features\n",
    "There are few things to note if we use default arguments of CountVectorizer:\n",
    "1. Everything will be in lowercase <br>\n",
    "2. Words less than two letters will not be included (There is no I) <br>\n",
    "3. Punctuations will be removed <br>\n",
    "4. There will be no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'dogs', 'hate', 'hobby', 'is', 'knitting', 'love', 'my', 'passion']\n"
     ]
    }
   ],
   "source": [
    "# Print all the words \n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent features and count in a dataframe\n",
    "We create a dataframe which store features and their corresponding word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>dogs</th>\n",
       "      <th>hate</th>\n",
       "      <th>hobby</th>\n",
       "      <th>is</th>\n",
       "      <th>knitting</th>\n",
       "      <th>love</th>\n",
       "      <th>my</th>\n",
       "      <th>passion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  dogs  hate  hobby  is  knitting  love  my  passion\n",
       "0    0     1     0      0   0         0     1   0        0\n",
       "1    1     1     1      0   0         1     0   0        0\n",
       "2    1     0     0      1   1         1     0   2        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas \n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe and store the number of times a word appear in a document\n",
    "df = pd.DataFrame(word_count.toarray(), columns = cv.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can feed this into  machine learning algorithms to achieve the required task.\n",
    "\n",
    "We will learn to use XGBoost algorithm on the vectors generated from BoW to predict the sentiment of the news headlines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model\n",
    "\n",
    "In this notebook, we will learn to use XGBoost model and predict sentiment of the news headlines. The steps involved are:\n",
    "1. Read data\n",
    "2. Determine target variables\n",
    "3. Create predictor variables\n",
    "4. Split data into train and test \n",
    "5. Apply Bag of Words on train and test dataset\n",
    "6. Run XGBoost on the train dataset\n",
    "7. Predict sentiment scores on the test dataset\n",
    "8. Analyse the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>news_headline</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>URL</th>\n",
       "      <th>source_id</th>\n",
       "      <th>sentiment_class</th>\n",
       "      <th>sentiment_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999840</td>\n",
       "      <td>IMF chief: Beware of global deflation</td>\n",
       "      <td>2014-01-27 10:17:47-08:00</td>\n",
       "      <td>/video/data/2.0/video/business/2014/01/24/intv...</td>\n",
       "      <td>1248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012782</td>\n",
       "      <td>Cars for Sale - ToDrive.com</td>\n",
       "      <td>2014-01-27 10:17:47-08:00</td>\n",
       "      <td>http://www.todrive.com/</td>\n",
       "      <td>1303</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995595</td>\n",
       "      <td>Info Edge CFO Raghuvanshi resigns</td>\n",
       "      <td>2014-01-27 10:17:47-08:00</td>\n",
       "      <td>http://www.thehindu.com/business/Industry/info...</td>\n",
       "      <td>1239</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012786</td>\n",
       "      <td>Weak company earnings drag US stocks mostly lower</td>\n",
       "      <td>2014-01-27 10:17:47-08:00</td>\n",
       "      <td>//www.suntimes.com/business/24993766-420/weak-...</td>\n",
       "      <td>1303</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012787</td>\n",
       "      <td>Some workers set to reach $100K pay in Boeing ...</td>\n",
       "      <td>2014-01-27 10:17:47-08:00</td>\n",
       "      <td>//www.suntimes.com/business/24725356-420/some-...</td>\n",
       "      <td>1303</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.0772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      news_headline  \\\n",
       "0     1999840              IMF chief: Beware of global deflation   \n",
       "1     2012782                        Cars for Sale - ToDrive.com   \n",
       "2     1995595                  Info Edge CFO Raghuvanshi resigns   \n",
       "3     2012786  Weak company earnings drag US stocks mostly lower   \n",
       "4     2012787  Some workers set to reach $100K pay in Boeing ...   \n",
       "\n",
       "                  time_stamp  \\\n",
       "0  2014-01-27 10:17:47-08:00   \n",
       "1  2014-01-27 10:17:47-08:00   \n",
       "2  2014-01-27 10:17:47-08:00   \n",
       "3  2014-01-27 10:17:47-08:00   \n",
       "4  2014-01-27 10:17:47-08:00   \n",
       "\n",
       "                                                 URL  source_id  \\\n",
       "0  /video/data/2.0/video/business/2014/01/24/intv...       1248   \n",
       "1                            http://www.todrive.com/       1303   \n",
       "2  http://www.thehindu.com/business/Industry/info...       1239   \n",
       "3  //www.suntimes.com/business/24993766-420/weak-...       1303   \n",
       "4  //www.suntimes.com/business/24725356-420/some-...       1303   \n",
       "\n",
       "   sentiment_class  sentiment_scores  \n",
       "0                0            0.0000  \n",
       "1                0            0.0000  \n",
       "2               -1           -0.3182  \n",
       "3               -1           -0.7184  \n",
       "4               -1           -0.0772  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read news sentiment data\n",
    "news_sentiment_data = pd.read_csv('news_headline_sentiments.csv')\n",
    "news_sentiment_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine target variables\n",
    "Here target variable is to predict sentiment class of the news headlines.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store sentiment_class in y\n",
    "y = news_sentiment_data.sentiment_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictor variables\n",
    "Here predictor variables are news headlines which are used to predict target variable which is sentiment class of the news headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store news healines in X\n",
    "X=news_sentiment_data.news_headline\n",
    "\n",
    "#Convert X in string if the value of x is not string\n",
    "X=[str(x) if type(x)!=str else x for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 80% of our data to train and the rest 20% to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio=0.2\n",
    "train_ratio=1-test_ratio\n",
    "num_train=int(train_ratio*len(X))\n",
    "#Train data set\n",
    "X_train=X[:num_train]\n",
    "y_train=y[:num_train]\n",
    "#Test data set\n",
    "X_test=X[num_train:]\n",
    "y_test=y[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Bag of Words on train and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert training and testing dataset into the bag of words vector. \n",
    "\n",
    "For that first we process the news headlines which consists of \n",
    "1. converting text to lower case\n",
    "2. removing stop words such as the, and, of, etc.\n",
    "\n",
    "We then pass the processed news headlines into `CountVectorizer` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize CountVectorizer and required arguments to process the data\n",
    "count_vectorizer = CountVectorizer(stop_words='english', lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the model on train dataet\n",
    "X_new_train = count_vectorizer.fit_transform(X_train)\n",
    "#fit:means the model learn from the data\n",
    "#transform: produce the output based on the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test dataset\n",
    "X_new_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run XGBoost on the train dataset\n",
    "\n",
    "To train our model, we pass the the vectors to XGBoost model. We use `XGBClassifier` and pass the following parameters:\n",
    "\n",
    "1. <b>max_depth:</b>  limits the number of nodes in the tree\n",
    "2. <b>n_estimators:</b> number of trees to create "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import XGBClassifier from xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Instantiate XGBClassifier\n",
    "xg = XGBClassifier(max_depth = 6, n_estimators = 100)\n",
    "\n",
    "# Fit the model on train dataset\n",
    "xg_model = xg.fit(X_new_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Now the model is trained, we predict the sentiment class using the test dataset. We use `predict` function on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment class on the test dataset\n",
    "prediction = xg_model.predict(X_new_test)\n",
    "#remind:X_new_test = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    " We use confusion matrix, classification report and prediction accuracy to examine the performance of the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56110  33451   5551]\n",
      " [  1797 178694   3528]\n",
      " [  4097  36928  79845]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "print(confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.59      0.71     95112\n",
      "           0       0.72      0.97      0.83    184019\n",
      "           1       0.90      0.66      0.76    120870\n",
      "\n",
      "   micro avg       0.79      0.79      0.79    400001\n",
      "   macro avg       0.84      0.74      0.77    400001\n",
      "weighted avg       0.82      0.79      0.78    400001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7866205334486663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "print(accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
